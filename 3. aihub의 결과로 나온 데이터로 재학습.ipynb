{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e30881d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66df56f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_file = 'posnega_model1/pytorch_model.bin'\n",
    "output_config_file = 'posnega_model1/config.json'\n",
    "output_vocab_file = 'posnega_model1/vocab.txt'\n",
    "\n",
    "config = BertConfig.from_json_file(output_config_file)\n",
    "model = BertForSequenceClassification(config)\n",
    "state_dict = torch.load(output_model_file)\n",
    "model.load_state_dict(state_dict)\n",
    "tokenizer = BertTokenizer(output_vocab_file, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfbd6c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# GPU 디바이스 이름 구함\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# GPU 디바이스 이름 검사\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44ba8d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# 디바이스 설정\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available, using the CPU instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b50d00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터 변환\n",
    "def convert_input_data(sentences):\n",
    "\n",
    "    # BERT의 토크나이저로 문장을 토큰으로 분리\n",
    "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "    # 입력 토큰의 최대 시퀀스 길이\n",
    "    MAX_LEN = 128\n",
    "\n",
    "    # 토큰을 숫자 인덱스로 변환\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "    \n",
    "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    # 어텐션 마스크 초기화\n",
    "    attention_masks = []\n",
    "\n",
    "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
    "    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "\n",
    "    # 데이터를 파이토치의 텐서로 변환\n",
    "    inputs = torch.tensor(input_ids)\n",
    "    masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return inputs, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48b562c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "# 문장 테스트\n",
    "def test_sentences(sentences):\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 문장을 입력 데이터로 변환\n",
    "    inputs, masks = convert_input_data(sentences)\n",
    "\n",
    "    # 데이터를 GPU에 넣음\n",
    "    b_input_ids = inputs.to(device)\n",
    "    b_input_mask = masks.to(device)\n",
    "            \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(torch.tensor(b_input_ids).to(device).long(), \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "234fa6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeepLearning_1\\anaconda3\\envs\\windup\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.2392924  3.5598252]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['완봉승을 기록한 워윅 서폴드의 공이 가장 컸다'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db1e98ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>“대구 힘내세요” “기억할게요”…희망 주는 ‘야구’가 돌아왔다ㆍ무관중 개막 삼성 -...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>그럼에도 불구하고, 개막을 오래 기다린 SK팬이라면 허망할 수밖에 없는 완패였다</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>어린이들이 가득 차야 할 대구 삼성라이온즈파크 외야 관중석에는 ‘힘내라 대한민국 ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>마지막까지 힘을 모아 함께 극복합시다!’라는 대형 현수막이 걸렸다</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>연고팀 삼성이 코로나19로 어려움을 겪은 대구·경북 주민들을 향해 보내는 기원 메...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25284</th>\n",
       "      <td>25550.0</td>\n",
       "      <td>타선지원이 아쉬웠다</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25285</th>\n",
       "      <td>25551.0</td>\n",
       "      <td>1-0으로 앞선 7회초 선두 타자 사구와 볼넷에 이어 번트 수비를 하다 3루에 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25286</th>\n",
       "      <td>25552.0</td>\n",
       "      <td>두번째 투수 최지광이 실점하면서 최채흥의 승리는 물거품이 됐다</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25287</th>\n",
       "      <td>25553.0</td>\n",
       "      <td>하지만 이날 최채흥의 경기 운영 능력은 만점에 가까웠다</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25288</th>\n",
       "      <td>25554.0</td>\n",
       "      <td>최채흥의 '조정능력'을 꿰뚫어 본 허파고의 예언이 현실이 되는 순간이었다</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25289 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                           sentence  label\n",
       "0             0.0  “대구 힘내세요” “기억할게요”…희망 주는 ‘야구’가 돌아왔다ㆍ무관중 개막 삼성 -...    1.0\n",
       "1             1.0       그럼에도 불구하고, 개막을 오래 기다린 SK팬이라면 허망할 수밖에 없는 완패였다    0.0\n",
       "2             2.0   어린이들이 가득 차야 할 대구 삼성라이온즈파크 외야 관중석에는 ‘힘내라 대한민국 ...    1.0\n",
       "3             3.0               마지막까지 힘을 모아 함께 극복합시다!’라는 대형 현수막이 걸렸다    1.0\n",
       "4             4.0   연고팀 삼성이 코로나19로 어려움을 겪은 대구·경북 주민들을 향해 보내는 기원 메...    1.0\n",
       "...           ...                                                ...    ...\n",
       "25284     25550.0                                         타선지원이 아쉬웠다    0.0\n",
       "25285     25551.0    1-0으로 앞선 7회초 선두 타자 사구와 볼넷에 이어 번트 수비를 하다 3루에 ...    0.0\n",
       "25286     25552.0                 두번째 투수 최지광이 실점하면서 최채흥의 승리는 물거품이 됐다    1.0\n",
       "25287     25553.0                     하지만 이날 최채흥의 경기 운영 능력은 만점에 가까웠다    1.0\n",
       "25288     25554.0           최채흥의 '조정능력'을 꿰뚫어 본 허파고의 예언이 현실이 되는 순간이었다    0.0\n",
       "\n",
       "[25289 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tuning\n",
    "train = pd.read_csv('finetune1.csv', encoding='cp949')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bbd8df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>“대구 힘내세요” “기억할게요”…희망 주는 ‘야구’가 돌아왔다ㆍ무관중 개막 삼성 -...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>그럼에도 불구하고, 개막을 오래 기다린 SK팬이라면 허망할 수밖에 없는 완패였다</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>어린이들이 가득 차야 할 대구 삼성라이온즈파크 외야 관중석에는 ‘힘내라 대한민국 ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>마지막까지 힘을 모아 함께 극복합시다!’라는 대형 현수막이 걸렸다</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>연고팀 삼성이 코로나19로 어려움을 겪은 대구·경북 주민들을 향해 보내는 기원 메...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25284</th>\n",
       "      <td>25550.0</td>\n",
       "      <td>타선지원이 아쉬웠다</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25285</th>\n",
       "      <td>25551.0</td>\n",
       "      <td>1-0으로 앞선 7회초 선두 타자 사구와 볼넷에 이어 번트 수비를 하다 3루에 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25286</th>\n",
       "      <td>25552.0</td>\n",
       "      <td>두번째 투수 최지광이 실점하면서 최채흥의 승리는 물거품이 됐다</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25287</th>\n",
       "      <td>25553.0</td>\n",
       "      <td>하지만 이날 최채흥의 경기 운영 능력은 만점에 가까웠다</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25288</th>\n",
       "      <td>25554.0</td>\n",
       "      <td>최채흥의 '조정능력'을 꿰뚫어 본 허파고의 예언이 현실이 되는 순간이었다</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20770 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                           sentence  label\n",
       "0             0.0  “대구 힘내세요” “기억할게요”…희망 주는 ‘야구’가 돌아왔다ㆍ무관중 개막 삼성 -...    1.0\n",
       "1             1.0       그럼에도 불구하고, 개막을 오래 기다린 SK팬이라면 허망할 수밖에 없는 완패였다    0.0\n",
       "2             2.0   어린이들이 가득 차야 할 대구 삼성라이온즈파크 외야 관중석에는 ‘힘내라 대한민국 ...    1.0\n",
       "3             3.0               마지막까지 힘을 모아 함께 극복합시다!’라는 대형 현수막이 걸렸다    1.0\n",
       "4             4.0   연고팀 삼성이 코로나19로 어려움을 겪은 대구·경북 주민들을 향해 보내는 기원 메...    1.0\n",
       "...           ...                                                ...    ...\n",
       "25284     25550.0                                         타선지원이 아쉬웠다    0.0\n",
       "25285     25551.0    1-0으로 앞선 7회초 선두 타자 사구와 볼넷에 이어 번트 수비를 하다 3루에 ...    0.0\n",
       "25286     25552.0                 두번째 투수 최지광이 실점하면서 최채흥의 승리는 물거품이 됐다    1.0\n",
       "25287     25553.0                     하지만 이날 최채흥의 경기 운영 능력은 만점에 가까웠다    1.0\n",
       "25288     25554.0           최채흥의 '조정능력'을 꿰뚫어 본 허파고의 예언이 현실이 되는 순간이었다    0.0\n",
       "\n",
       "[20770 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.dropna(axis=0)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "184867b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    float64\n",
       "sentence       object\n",
       "label           int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.astype({'label':'int'})\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e70a4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    “대구 힘내세요” “기억할게요”…희망 주는 ‘야구’가 돌아왔다ㆍ무관중 개막 삼성 -...\n",
       "1         그럼에도 불구하고, 개막을 오래 기다린 SK팬이라면 허망할 수밖에 없는 완패였다\n",
       "2     어린이들이 가득 차야 할 대구 삼성라이온즈파크 외야 관중석에는 ‘힘내라 대한민국 ...\n",
       "3                 마지막까지 힘을 모아 함께 극복합시다!’라는 대형 현수막이 걸렸다\n",
       "4     연고팀 삼성이 코로나19로 어려움을 겪은 대구·경북 주민들을 향해 보내는 기원 메...\n",
       "5      지난 2월 일본 오키나와에서 스프링캠프를 치를 때까지만 해도 삼성은 야구를 꿈꾸...\n",
       "6                   대구·경북 지역은 코로나19 확진자가 가장 많이 나온 곳이었다\n",
       "7                   삼성은 일본의 입국 제한 조치 여파로 3월7일 급히 짐을 쌌다\n",
       "8                 귀국 뒤에도 철저한 규제 속에서 고립된 채 조용히 시즌을 준비했다\n",
       "9      수많은 이들의 노력 끝에 코로나19 사태가 진정세에 접어들면서 올 것 같지 않았...\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리뷰 문장 추출\n",
    "sentences = train['sentence']\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd799618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] “대구 힘내세요” “기억할게요”…희망 주는 ‘야구’가 돌아왔다ㆍ무관중 개막 삼성 - NC전 관중석엔 “함께 극복을” 현수막 ㆍ코로나19 의료진 응원 영상에 선수들도 ‘덕분에’ 손동작 ㆍ각 구장 깜짝 시구·재치있는 플래카드 ‘야구의 계절’ 환영  관중은 없어도 오늘은 좋은 날 SK 치어리더들이 5일 인천 SK행복드림구장에서 열린 한화와의 KBO리그 개막전에서 온라인으로 생중계되는 응원을 펼치고 있다 [SEP]',\n",
       " '[CLS] 그럼에도 불구하고, 개막을 오래 기다린 SK팬이라면 허망할 수밖에 없는 완패였다 [SEP]',\n",
       " '[CLS]  어린이들이 가득 차야 할 대구 삼성라이온즈파크 외야 관중석에는 ‘힘내라 대한민국 그동안 수고하셨습니다 [SEP]',\n",
       " '[CLS]  마지막까지 힘을 모아 함께 극복합시다!’라는 대형 현수막이 걸렸다 [SEP]',\n",
       " '[CLS]  연고팀 삼성이 코로나19로 어려움을 겪은 대구·경북 주민들을 향해 보내는 기원 메시지였다 [SEP]',\n",
       " '[CLS]   지난 2월 일본 오키나와에서 스프링캠프를 치를 때까지만 해도 삼성은 야구를 꿈꾸기 어려웠다 [SEP]',\n",
       " '[CLS]  대구·경북 지역은 코로나19 확진자가 가장 많이 나온 곳이었다 [SEP]',\n",
       " '[CLS]  삼성은 일본의 입국 제한 조치 여파로 3월7일 급히 짐을 쌌다 [SEP]',\n",
       " '[CLS]  귀국 뒤에도 철저한 규제 속에서 고립된 채 조용히 시즌을 준비했다 [SEP]',\n",
       " '[CLS]   수많은 이들의 노력 끝에 코로나19 사태가 진정세에 접어들면서 올 것 같지 않았던 개막이 다가왔다 [SEP]']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT의 입력 형식에 맞게 변환\n",
    "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b646140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라벨 추출\n",
    "labels = train['label'].values\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "987d9042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] “대구 힘내세요” “기억할게요”…희망 주는 ‘야구’가 돌아왔다ㆍ무관중 개막 삼성 - NC전 관중석엔 “함께 극복을” 현수막 ㆍ코로나19 의료진 응원 영상에 선수들도 ‘덕분에’ 손동작 ㆍ각 구장 깜짝 시구·재치있는 플래카드 ‘야구의 계절’ 환영  관중은 없어도 오늘은 좋은 날 SK 치어리더들이 5일 인천 SK행복드림구장에서 열린 한화와의 KBO리그 개막전에서 온라인으로 생중계되는 응원을 펼치고 있다 [SEP]\n",
      "['[CLS]', '[UNK]', '대', '##구', '힘', '##내', '##세', '##요', '[UNK]', '[UNK]', '기', '##억', '##할', '##게', '##요', '[UNK]', '[UNK]', '희', '##망', '주', '##는', '[UNK]', '야구', '[UNK]', '가', '돌', '##아', '##왔다', '##ㆍ', '##무', '##관', '##중', '개', '##막', '삼', '##성', '-', 'NC', '##전', '관', '##중', '##석', '##엔', '[UNK]', '함께', '극', '##복', '##을', '[UNK]', '현', '##수', '##막', 'ㆍ', '##코', '##로', '##나', '##19', '의', '##료', '##진', '응', '##원', '영', '##상', '##에', '선수', '##들', '##도', '[UNK]', '덕', '##분에', '[UNK]', '손', '##동', '##작', 'ㆍ', '##각', '구', '##장', '깜', '##짝', '시', '##구', '·', '재', '##치', '##있는', '플', '##래', '##카', '##드', '[UNK]', '야구', '##의', '계', '##절', '[UNK]', '환', '##영', '관', '##중', '##은', '없', '##어', '##도', '오', '##늘', '##은', '좋은', '날', 'SK', '치', '##어', '##리', '##더', '##들이', '5일', '인', '##천', 'SK', '##행', '##복', '##드', '##림', '##구', '##장에서', '열린', '한', '##화', '##와의', 'KB', '##O', '##리그', '개', '##막', '##전에서', '온', '##라', '##인', '##으로', '생', '##중', '##계', '##되는', '응', '##원을', '펼', '##치고', '있다', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "print (sentences[0])\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad6fabaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   101,    100,   9069,  17196,  10028,  31605,  24982,  48549,\n",
       "          100,    100,   8932,  91837,  14843,  14153,  48549,    100,\n",
       "          100,  10023,  89292,   9689,  11018,    100, 106603,    100,\n",
       "         8843,   9091,  16985,  72995, 111836,  32537,  20595,  41693,\n",
       "         8857, 118907,   9410,  17138,    118,  55838,  16617,   8900,\n",
       "        41693,  40958,  86933,    100,  19653,   8925,  70915,  10622,\n",
       "          100,   9978,  15891, 118907,   2070,  25517,  11261,  16439,\n",
       "        54055,   9637,  38688,  18623,   9636,  14279,   9574,  14871,\n",
       "        10530,  78930,  27023,  12092,    100,   9075, 110355,    100,\n",
       "         9450,  18778,  38709,   2070,  66540,   8908,  13890,   8943,\n",
       "       119236,   9485,  17196,    217,   9659,  18622,  84177,   9944,\n",
       "        37388,  24206,  15001,    100, 106603,  10459,   8887,  58931,\n",
       "          100,   9995,  30858,   8900,  41693,  10892,   9555,  12965,\n",
       "        12092,   9580, 118762,  10892,  79633,   8985,  21275,   9779,\n",
       "        12965,  12692,  54141,  20173,  44015,   9640,  38631,  21275,\n",
       "        25549,  70915,  15001,  67527,  17196,  96006,  66421,   9954])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력 토큰의 최대 시퀀스 길이\n",
    "MAX_LEN = 128\n",
    "\n",
    "# 토큰을 숫자 인덱스로 변환\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19a58597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 마스크 초기화\n",
    "attention_masks = []\n",
    "\n",
    "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
    "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "\n",
    "print(attention_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25f53ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   101,   9484,  12692,   9995,  20309,  12178,   9410,  17138,  39900,\n",
      "         18392,   9580,  31531,  48253,   8908,  11261,  17196,   8888, 119259,\n",
      "          9477,  24206,  10739, 118795,  11489,  66421,  23607, 102574,  21711,\n",
      "         17196,   9410,  17138,   9157,  10739,  37093,  24891,  12638,   9838,\n",
      "        119169,  10025,  81483,  24891,  10459,  81785,   9484,  12692,  11102,\n",
      "          9410,  17138,  78930,  20173,  86015,  10003,   9995,  20309,  12453,\n",
      "         11506,    102,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0], dtype=torch.int32)\n",
      "tensor(1, dtype=torch.int32)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "tensor([  101,  9484, 27852,  9967, 11102,  9711, 41693, 28143,  9279, 11489,\n",
      "         9410, 53371,  9954, 56999,  9527, 12092, 12490,   102,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0],\n",
      "       dtype=torch.int32)\n",
      "tensor(0, dtype=torch.int32)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# 훈련셋과 검증셋으로 분리\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n",
    "                                                                                    labels, \n",
    "                                                                                    random_state=2018, \n",
    "                                                                                    test_size=0.1)\n",
    "\n",
    "# 어텐션 마스크를 훈련셋과 검증셋으로 분리\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n",
    "                                                       input_ids,\n",
    "                                                       random_state=2018, \n",
    "                                                       test_size=0.1)\n",
    "\n",
    "# 데이터를 파이토치의 텐서로 변환\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)\t\t\t\t\n",
    "\n",
    "print(train_inputs[0])\n",
    "print(train_labels[0])\n",
    "print(train_masks[0])\n",
    "print(validation_inputs[0])\n",
    "print(validation_labels[0])\n",
    "print(validation_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12e00d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 사이즈\n",
    "batch_size = 8\n",
    "\n",
    "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
    "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86477cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저 설정\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # 학습률\n",
    "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
    "                )\n",
    "\n",
    "# 에폭수\n",
    "epochs = 4\n",
    "\n",
    "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# 처음에 학습률을 조금씩 변화시키는 스케줄러 생성\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "656126a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 계산 함수\n",
    "def flat_accuracy(preds, labels):\n",
    "    \n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2b752d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간 표시 함수\n",
    "def format_time(elapsed):\n",
    "\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98598b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeepLearning_1\\anaconda3\\envs\\windup\\lib\\site-packages\\ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   500  of  2,337.    Elapsed: 0:01:13.\n",
      "  Batch 1,000  of  2,337.    Elapsed: 0:02:26.\n",
      "  Batch 1,500  of  2,337.    Elapsed: 0:03:39.\n",
      "  Batch 2,000  of  2,337.    Elapsed: 0:04:52.\n",
      "\n",
      "  Average training loss: 0.38\n",
      "  Training epcoh took: 0:05:41\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeepLearning_1\\anaconda3\\envs\\windup\\lib\\site-packages\\ipykernel_launcher.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.87\n",
      "  Validation took: 0:00:08\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of  2,337.    Elapsed: 0:01:13.\n",
      "  Batch 1,000  of  2,337.    Elapsed: 0:02:25.\n",
      "  Batch 1,500  of  2,337.    Elapsed: 0:03:38.\n",
      "  Batch 2,000  of  2,337.    Elapsed: 0:04:51.\n",
      "\n",
      "  Average training loss: 0.29\n",
      "  Training epcoh took: 0:05:39\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.89\n",
      "  Validation took: 0:00:08\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of  2,337.    Elapsed: 0:01:12.\n",
      "  Batch 1,000  of  2,337.    Elapsed: 0:02:24.\n",
      "  Batch 1,500  of  2,337.    Elapsed: 0:03:36.\n",
      "  Batch 2,000  of  2,337.    Elapsed: 0:04:48.\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epcoh took: 0:05:36\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.90\n",
      "  Validation took: 0:00:08\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of  2,337.    Elapsed: 0:01:12.\n",
      "  Batch 1,000  of  2,337.    Elapsed: 0:02:23.\n",
      "  Batch 1,500  of  2,337.    Elapsed: 0:03:35.\n",
      "  Batch 2,000  of  2,337.    Elapsed: 0:04:46.\n",
      "\n",
      "  Average training loss: 0.14\n",
      "  Training epcoh took: 0:05:35\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.90\n",
      "  Validation took: 0:00:08\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# 재현을 위해 랜덤시드 고정\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "# 그래디언트 초기화\n",
    "model.zero_grad()\n",
    "\n",
    "# 에폭만큼 반복\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # 시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 로스 초기화\n",
    "    total_loss = 0\n",
    "\n",
    "    # 훈련모드로 변경\n",
    "    model.train()\n",
    "        \n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # 경과 정보 표시\n",
    "        if step % 500 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "       \n",
    "        # Forward 수행                \n",
    "        outputs = model(torch.tensor(b_input_ids).to(device).long(), \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask, \n",
    "                        labels=b_labels.long())\n",
    "        \n",
    "        # 로스 구함\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # 총 로스 계산\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward 수행으로 그래디언트 계산\n",
    "        loss.backward()\n",
    "\n",
    "        # 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 스케줄러로 학습률 감소\n",
    "        scheduler.step()\n",
    "\n",
    "        # 그래디언트 초기화\n",
    "        model.zero_grad()\n",
    "\n",
    "    # 평균 로스 계산\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    #시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 변수 초기화\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for batch in validation_dataloader:\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # 그래디언트 계산 안함\n",
    "        with torch.no_grad():     \n",
    "            # Forward 수행\n",
    "            outputs = model(torch.tensor(b_input_ids).to(device).long(), \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # 로스 구함\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # CPU로 데이터 이동\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87b33086",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "# 문장 테스트\n",
    "def test_sentences(sentences):\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 문장을 입력 데이터로 변환\n",
    "    inputs, masks = convert_input_data(sentences)\n",
    "\n",
    "    # 데이터를 GPU에 넣음\n",
    "    b_input_ids = inputs.to(device)\n",
    "    b_input_mask = masks.to(device)\n",
    "            \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(torch.tensor(b_input_ids).to(device).long(), \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60516f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.8803    -3.1308494]]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeepLearning_1\\anaconda3\\envs\\windup\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['맷 윌리엄스 감독은 손톱 상태가 투구가 어렵다고 판단하고 박준표를 대체 투수로 올렸다.'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c172f17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[OSEN=광주',\n",
       " ' 이선호 기자] KIA 타이거즈 좌완 이의리가 투구도중 손톱이 깨쳐 조기 강판했다',\n",
       " ' 이의리는 12일 광주-기아 챔피언스필드에서 열린 NC 다이노스와의 경기에 선발등판해 3이닝을 마치고 등판을 마감했다',\n",
       " ' 투구성적은 4피안타 3볼넷 5탈삼진 1실점이었다',\n",
       " ' 0-1로 뒤진 가운데 내려가 시즌 5승 사냥은 불발에 그쳤다',\n",
       " ' 6경기 연속 승리를 거두지 못했다',\n",
       " ' 이의리의 강판 이유는 왼손 중지 손톱이 깨지는 부상 때문이었다',\n",
       " ' 맷 윌리엄스 감독은 손톱 상태가 투구가\\xa0어렵다고 판단하고 박준표를 대체 투수로 올렸다',\n",
       " ' 이의리는 초반부터 많은 투구로 고전했다',\n",
       " ' 1회초 최정원 안타, 정현 볼넷을 내주고 무사 1,2루에 몰렸다',\n",
       " ' 세 타자를 삼진 2개와 범타로 막았으나 22구를 던졌다',\n",
       " ' 2회는 1안타 무실점으로 넘겼으나 3회 제구가 흔들렸다',\n",
       " ' 1사후 정현\\xa0볼넷에 이어\\xa02사후 양의지를 볼넷을 허용하고 알테어에게 중전적시타를 맞고 첫 실점했다',\n",
       " ' 전민수를 2루 뜬공으로 잡고 이닝을 마감했다',\n",
       " ' 3회까지 9개의 아웃카운트를 잡는데 69구를 던졌다',\n",
       " ' 스트라이크는 38개에 그쳤다',\n",
       " ' 추후 등판 일정은 손톱의 상태에 따라 유동적이다']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = '[OSEN=광주. 이선호 기자] KIA 타이거즈 좌완 이의리가 투구도중 손톱이 깨쳐 조기 강판했다. 이의리는 12일 광주-기아 챔피언스필드에서 열린 NC 다이노스와의 경기에 선발등판해 3이닝을 마치고 등판을 마감했다. 투구성적은 4피안타 3볼넷 5탈삼진 1실점이었다. 0-1로 뒤진 가운데 내려가 시즌 5승 사냥은 불발에 그쳤다. 6경기 연속 승리를 거두지 못했다. 이의리의 강판 이유는 왼손 중지 손톱이 깨지는 부상 때문이었다. 맷 윌리엄스 감독은 손톱 상태가 투구가 어렵다고 판단하고 박준표를 대체 투수로 올렸다. 이의리는 초반부터 많은 투구로 고전했다. 1회초 최정원 안타, 정현 볼넷을 내주고 무사 1,2루에 몰렸다. 세 타자를 삼진 2개와 범타로 막았으나 22구를 던졌다. 2회는 1안타 무실점으로 넘겼으나 3회 제구가 흔들렸다. 1사후 정현 볼넷에 이어 2사후 양의지를 볼넷을 허용하고 알테어에게 중전적시타를 맞고 첫 실점했다. 전민수를 2루 뜬공으로 잡고 이닝을 마감했다. 3회까지 9개의 아웃카운트를 잡는데 69구를 던졌다. 스트라이크는 38개에 그쳤다. 추후 등판 일정은 손톱의 상태에 따라 유동적이다.'\n",
    "sentences = article.split('.')[:-1]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bc2d7f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeepLearning_1\\anaconda3\\envs\\windup\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OSEN=광주 label:  1\n",
      "myjudge? 0\n",
      " 이선호 기자] KIA 타이거즈 좌완 이의리가 투구도중 손톱이 깨쳐 조기 강판했다 label:  0\n",
      "myjudge? 0\n",
      " 이의리는 12일 광주-기아 챔피언스필드에서 열린 NC 다이노스와의 경기에 선발등판해 3이닝을 마치고 등판을 마감했다 label:  0\n",
      "myjudge? 0\n",
      " 투구성적은 4피안타 3볼넷 5탈삼진 1실점이었다 label:  1\n",
      "myjudge? 1\n",
      " 0-1로 뒤진 가운데 내려가 시즌 5승 사냥은 불발에 그쳤다 label:  0\n",
      "myjudge? 0\n",
      " 6경기 연속 승리를 거두지 못했다 label:  0\n",
      "myjudge? 0\n",
      " 이의리의 강판 이유는 왼손 중지 손톱이 깨지는 부상 때문이었다 label:  0\n",
      "myjudge? 0\n",
      " 맷 윌리엄스 감독은 손톱 상태가 투구가 어렵다고 판단하고 박준표를 대체 투수로 올렸다 label:  0\n",
      "myjudge? 0\n",
      " 이의리는 초반부터 많은 투구로 고전했다 label:  1\n",
      "myjudge? 0\n",
      " 1회초 최정원 안타, 정현 볼넷을 내주고 무사 1,2루에 몰렸다 label:  0\n",
      "myjudge? 0\n",
      " 세 타자를 삼진 2개와 범타로 막았으나 22구를 던졌다 label:  1\n",
      "myjudge? 0\n",
      " 2회는 1안타 무실점으로 넘겼으나 3회 제구가 흔들렸다 label:  0\n",
      "myjudge? 0\n",
      " 1사후 정현 볼넷에 이어 2사후 양의지를 볼넷을 허용하고 알테어에게 중전적시타를 맞고 첫 실점했다 label:  0\n",
      "myjudge? 0\n",
      " 전민수를 2루 뜬공으로 잡고 이닝을 마감했다 label:  0\n",
      "myjudge? 1\n",
      " 3회까지 9개의 아웃카운트를 잡는데 69구를 던졌다 label:  0\n",
      "myjudge? 0\n",
      " 스트라이크는 38개에 그쳤다 label:  0\n",
      "myjudge? 0\n",
      " 추후 등판 일정은 손톱의 상태에 따라 유동적이다 label:  0\n",
      "myjudge? 0\n",
      "이 기사는 부정\n"
     ]
    }
   ],
   "source": [
    "negative = []\n",
    "positive = []\n",
    "myjudge = []\n",
    "for s in sentences:\n",
    "#     if(np.argmax(test_sentences([s])) == 1):\n",
    "#         positive.append('*')\n",
    "#     else:\n",
    "#         negative.append('*')\n",
    "    \n",
    "    print(s, 'label: ', np.argmax(test_sentences([s])))\n",
    "    judge = int(input('myjudge? '))\n",
    "    myjudge.append(judge)\n",
    "    if judge == 1:\n",
    "        positive.append('*')\n",
    "    else:\n",
    "        negative.append('*')\n",
    "    \n",
    "if len(positive) > len(negative):\n",
    "    print('이 기사는 긍정')\n",
    "elif len(positive) < len(negative):\n",
    "    print('이 기사는 부정')\n",
    "else:\n",
    "    print('이 기사는 중립')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c3a12785",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "79b76794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6427ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning test\n",
    "test= pd.read_csv('dataset/finetuning_aihub_model.csv', encoding='cp949')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f5b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.dropna(axis=0)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effa07c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.astype({'label':'int'})\n",
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbaf2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리뷰 문장 추출\n",
    "sentences = test['sentence']\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03180b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT의 입력 형식에 맞게 변환\n",
    "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da60f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨 추출\n",
    "labels = test['label'].values\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563d6ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "print (sentences[0])\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6fa3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 토큰의 최대 시퀀스 길이\n",
    "MAX_LEN = 128\n",
    "\n",
    "# 토큰을 숫자 인덱스로 변환\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbdb48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 마스크 초기화\n",
    "attention_masks = []\n",
    "\n",
    "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
    "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "\n",
    "print(attention_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd13f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 파이토치의 텐서로 변환\n",
    "test_inputs = torch.tensor(input_ids)\n",
    "test_labels = torch.tensor(labels)\n",
    "test_masks = torch.tensor(attention_masks)\n",
    "\n",
    "print(test_inputs[0])\n",
    "print(test_labels[0])\n",
    "print(test_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49afcdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 사이즈\n",
    "batch_size = 16\n",
    "\n",
    "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
    "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d530cb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#시작 시간 설정\n",
    "t0 = time.time()\n",
    "\n",
    "# 평가모드로 변경\n",
    "model.eval()\n",
    "\n",
    "# 변수 초기화\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "for step, batch in enumerate(test_dataloader):\n",
    "    # 경과 정보 표시\n",
    "    if step % 100 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
    "\n",
    "    # 배치를 GPU에 넣음\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # 배치에서 데이터 추출\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(torch.tensor(b_input_ids).to(device).long(),\n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "    \n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "print(\"\")\n",
    "print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef73367",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logits = test_sentences(['아내가 드디어 출산하게 되어서 정말 신이 나.'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3d2761",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = test['sentence']\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1ce8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for s in sentences:\n",
    "    label.append(np.argmax(test_sentences([s])))\n",
    "    print(s, 'label: ', np.argmax(test_sentences([s])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7455a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(label))\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf29b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung = {'sentence': sentences, 'label': label}\n",
    "samsungdf = pd.DataFrame(samsung)\n",
    "samsungdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00acbbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "samsungdf.to_csv('finetune1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "04e24a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('posnega_model2\\\\tokenizer_config.json',\n",
       " 'posnega_model2\\\\special_tokens_map.json',\n",
       " 'posnega_model2\\\\vocab.txt',\n",
       " 'posnega_model2\\\\added_tokens.json')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('posnega_model2')\n",
    "tokenizer.save_pretrained('posnega_model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507ebeeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "windup",
   "language": "python",
   "name": "windup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
